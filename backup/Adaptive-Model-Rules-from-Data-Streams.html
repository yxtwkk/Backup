<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Adaptive Model Rules from Data Streams | Yeeex</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><div id="link" rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"></div><div id="link" rel="stylesheet" href="https://libs.useso.com/js/font-awesome/4.2.0/css/font-awesome.min.css"></div><div id="link" rel="stylesheet" href="font-awesome-4.7.0/css/font-awesome.min.css"></div><link rel="stylesheet" href="https://libs.baidu.com/fontawesome/4.0.3/css/font-awesome.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Adaptive Model Rules from Data Streams</h1><a id="logo" href="/.">Yeeex</a><p class="description">愿自由且开阔</p></div><div id="nav-menu"><a href="/."><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Adaptive Model Rules from Data Streams</h1><div class="post-content"><p>Adaptive Model Rules from Data Streams ／AMRRules</p>
<p><strong>———————背景介绍————————</strong></p>
<p>Regression Analysis 回归分析 =&gt; dependent variable and a set of independent variables</p>
<p>model trees ／ regression rules =&gt; automatic feature selection  ／ robust to outliers &amp; irrelevant features  ／ 可解释性好 interpretability／modularity 模块化</p>
<p><strong>——————AMR Rules———————</strong></p>
<p>One-pass algorithm learning regression rules sets from time-evolving streams</p>
<p>初始化 conditions based on the attribute values </p>
<p>function -&gt; minimize the mean square error of the target attribute computed form the set of examples covered by rule</p>
<p>function可以是 target attribute 的constant/ mean ；linear combination of the attributes</p>
<p>each rule -&gt; online change detector -&gt; monitor the mean square error using the <strong>Page-Hinkley test</strong></p>
<p><strong>———————决策树问题————————-</strong></p>
<p>基本的决策树 ID3 需要计算各个属性的Information Gain 用于划分；当前选择该属性进行划分后，在下次划分时，就不再考虑这个属性，是在该属性的子集上进行，这会引起切分方式过于迅速的问题，ID3同样不能直接处理连续型特征</p>
<h5 id="分类回归树-CART-Classifictaion-and-Regression-Tree"><a href="#分类回归树-CART-Classifictaion-and-Regression-Tree" class="headerlink" title="分类回归树 CART Classifictaion and Regression Tree"></a>分类回归树 CART Classifictaion and Regression Tree</h5><p>一种二元切分方法</p>
<p><strong>分类</strong></p>
<p>分类回归树🌲是一棵二叉树，<strong>每个非叶子🍃节点都有两个孩子</strong>，与ID3不同的是，进行节点属性选择时，采用GINI指数为准则。ID3采用Information Gain为准则选择属性，偏向选择分支比较多的属性值</p>
<p><strong>回归</strong></p>
<p>（1）通过建树，可以得知，y对某个变量xi的依赖性，以及自变量之间关系的认识</p>
<p>（2）节点的每次分裂都把原样本空间划分为互不相交的两个子集。是一种贪心的爬山算法</p>
<p>（3）常采用最小平方误差LS作为划分标准</p>
<h5 id="模型树🌲-M5"><a href="#模型树🌲-M5" class="headerlink" title="模型树🌲 M5"></a>模型树🌲 M5</h5><p>（1）叶子节点不是常量，而是一个线性函数模型</p>
<p>（2）分割空间的标准不是降低平方误差，而是降低样本标准差；划分标准：将一个节点覆盖的样本Y值，即目标属性值，的标准差看作误差的度量，计算SDR(standard deviation reduction)</p>
<p>（3）模型树在处理高维数据时效果更好，且叶子节点采用线性函数模型，预测精度更高</p>
<p>（4）在叶子节点上，对本节点包含的实例，利用线性回归算法产生一个多元回归方程，得到线性模型</p>
<h5 id="基于规则的分类器"><a href="#基于规则的分类器" class="headerlink" title="基于规则的分类器"></a>基于规则的分类器</h5><p>（1）互斥规则：如果规则集R中不存在两条规则被同一条记录触发，则称规则集R中的规则是互斥的。这个性质确保每条记录至多被R中的一条规则覆盖。</p>
<p>（2）穷举规则：如果对属性值的任意组合，R中都存在一条规则加以覆盖，则称规则集R具有穷举覆盖。这个性质确保每一条记录都至少被R中的一条规则覆盖。</p>
<p>如果规则集不是互斥的，那么一条记录可能会被多条规则覆盖，这些规则可能会相互冲突，有两种解决方案：</p>
<p>（1）有序规则：规则集中的规则按照优先级降序排列。优先级的定义有多种方法，比如基于准确率、覆盖率、总描述长度或规则产生的顺序等。有序规则的规则集也称为决策表。</p>
<p>（2）无序规则：允许一条规则测试记录触发多条分类规则，把每条被触发规则的后件看作是对相应类的一次投票，然后计票确定测试记录的类标号。通常把记录指派到得票最多的类。</p>
<p><strong>—————-机器学习理论 霍夫丁不等式 Hoeffding probability bound———</strong></p>
<p>例子🌰：在一个罐子里，放着很多小球，有橘色和绿色两种，从罐中随机抓N个小球，假设罐中橘色小球的比例为μ，是未知的；但是抓出来的样本中，橘色小球的比例为ν是已知的；根据霍夫丁不等式Hoeffding’s Inequality可知，若N足够大，μ与ν可能相等。</p>
<p><strong>——————AMRules Adaptive Model Rules from High-Speed Data Streams————</strong></p>
<h5 id="数据流图-Data-Stream"><a href="#数据流图-Data-Stream" class="headerlink" title="数据流图 Data Stream"></a>数据流图 Data Stream</h5><p><img src="/backup/Users/yxtwkk/Documents/hexo/source/_posts/AMRules code.png" alt="AMRules code"></p>
<p><img src="/backup/Users/yxtwkk/Documents/hexo/source/_posts/Data Strem for AMRules.png" alt="Data Strem for AMRules"></p>
<p>Result Set（RS） &lt;- {} //用来存储整个规则树</p>
<p>defaultRule L &lt;- 0 //用来生成规则</p>
<p>对于数据流里的每一个训练样本，如果RS里有满足的训练样本：</p>
<p>（1）如果是ordered set 则 expansion the rule 第一条</p>
<p>（2）如果是unordered set, 则 expansion the rule每一条</p>
<p>每次输入的训练样本，根据Model的概要，分配到对应的cover的worker上边</p>
<p>如果没有cover的rule，则在model上训练default rules 并将对应的rules放到worker上</p>
<p>worker上对于rule的修改 要传回model上</p>
<p>同样，对于样本的predict也在model上进行</p>
<h5 id="Learning-a-Rule-Set"><a href="#Learning-a-Rule-Set" class="headerlink" title="Learning a Rule Set"></a><strong>Learning a Rule Set</strong></h5><p>AMRules 需要记录一个adaptive window值，每一条规则的sufficient statistics都是从这个adaptive window里获取的。当一个规则可以扩展时，landmark window将会reset</p>
<h5 id="Exapansion-of-a-Rule"><a href="#Exapansion-of-a-Rule" class="headerlink" title="Exapansion of a Rule"></a><strong>Exapansion of a Rule</strong></h5><p>在expand the rule之前，会更新这条rule的sufficient statistics</p>
<p>sufficient statistics：被规则覆盖的训练样本数目，训练误差的线性平方和，以及需要在splitting attribute里需要用到的参数。</p>
<p>在expand the rule之前，需要检测当前被规则覆盖的训练样本数目是否达$N_{min}$</p>
<p>选择划分属性 standard deviation reduction SDR</p>
<blockquote>
<p>It can be efficiently computed in a incremental way.</p>
</blockquote>
<p><img src="/backup/Users/yxtwkk/Documents/hexo/source/_posts/SDR formula.png" alt="SDR formula"></p>
<p>$sum(yi^2) = a$</p>
<p>$sum(yi)$ = b</p>
<p>$sd(S) =\sqrt{\frac{1}{N} <em>(N</em>a-\frac{1}{N}*b^2) } $</p>
<p>$b_{new} = b_{old}+ yi$</p>
<p>$a_{new} = a_{old} + yi^2$</p>
<blockquote>
<p>$h_A$ 表示某一个属性A，S表示整个样本，$S_{Left}$表示属性A将样本分成的左子树的样本子集</p>
<p>Hoeffding Bound 参考论文 《Mining high-speed data streams》</p>
</blockquote>
<p>在实际比较的过程中，需要用到以下几个参数：</p>
<p>（1）hueristic measure 采用 SDR；对于各个属性，计算SDR，选出其中greater的两个属性，$X_A$和$X_B$ （假设SDR($X_A$) &gt; SDR($X_B$)）</p>
<p>（2）计算ratio    <script type="math/tex">ratio</script> = <script type="math/tex">{SDR(X_B)} \over {SDR(X_A)}</script>  ;则ratio是一个[0,1]之间的值</p>
<p>（3）根据 Hoeffding Bound 计算 <script type="math/tex">\epsilon</script> = $\sqrt{\frac{R^2ln(1/\delta)}{2n}}$  其中 $R^2$ = 1</p>
<p>对于每一个属性$X_i$ , 根据属性的每个值$V_j$ 计算SDR，选出其中最好的两个属性$X_i$</p>
<p>计算$\epsilon$ 和ratio，并计算UpperBound = $ratio + \epsilon$</p>
<p>如果UpperBound &lt; 1 则会有1-$\epsilon$ 的confidenc 保证$X_A$就是最好的分支属性，则可以根据$X_A$的属性值，将规则扩展为 $X_A &gt; Vj$ 和$X_A \le Vj$</p>
<blockquote>
<p> 尽管训练样本的增加会带来$\epsilon$的减小，仍然无法找到一个较优的属性$X_A$，（对于二叉树的分支问题，容易出现属性的SDR值相似的情况）</p>
</blockquote>
<p>在上述这种情况下，利用$\tau$作为threshold阈值来表征容错能力。</p>
<p>当$ \epsilon$ 小于$\tau$，但是splliting criterion依然不满足时（即 UpperBound 不小于1），则选择SDR较大的那个属性作为split attribute</p>
<h5 id="Prediction-Strategies"><a href="#Prediction-Strategies" class="headerlink" title="Prediction Strategies"></a><strong>Prediction Strategies</strong></h5><p>set of rules 可以是 ordered rules 和 unordered rules</p>
<p><strong>ordered rules</strong> =&gt; only the first rule that cover an example is used to predict the target example</p>
<p><strong>unordered rules</strong> =&gt; all rules covering the example are used for prediction , the final prediction by <strong>aggregating predictions using mean</strong></p>
<p>AMRules里的每条规则，有三种预测策略：</p>
<p>（1）根据被规则覆盖的训练样本的 target attribute value的平均值</p>
<p>（2）independent  value的线性拟合</p>
<p>（3）自适应策略：选择两种策略中，选择具有具有较低平均绝对误差(mean absolute error MAE)的策略</p>
<p>MAE的计算需要两个参数：</p>
<p>（1）absolute deviations T :$T$ &lt;— $\alpha T + |\hat y-y|$</p>
<p>（2）训练样本数N: $N$ &lt;— $\alpha N +1$</p>
<p>其中，$\hat y$是根据训练模型得到的值，$\alpha$是控制新老样本所占的比重的比重值，在(0,1)</p>
<p>AMRules里的每条规则都是拟合一个，采用incremental gradient descent method 梯度下降的方式。初始化，先对各个权重赋一个随机的初始值[-1,1]。当一个新的训练样本到来时，需要用训练样本更新权重$w_i$&lt;—  $w_i + \eta(\hat{y} - y)$其中，$\hat{y}$ 是根据规则拟合的output，$y$是训练样本标记的真实值，$\eta$是学习率</p>
<h5 id="Change-Detection-用来剪枝"><a href="#Change-Detection-用来剪枝" class="headerlink" title="Change Detection (用来剪枝)"></a>Change Detection (用来剪枝)</h5><p>利用Page-Hinckley （PH）change detection test 监控每条规则的错误</p>
<p>当出现一个带标签的数据，根据先前训练得到的模型，计算MSE或MAD，然后利用PH test监控评估，计算公式：$m_T$ = $\sum_{t=1}^T(x_t - \overline x_T - \delta)$</p>
<p>$m_T​$ ：cumulative varible ，到当下这个时刻，观测值和观测值的平均值之差</p>
<p>其中，$x_t$是观测值，根据训练模型和训练样本得到的观测值；</p>
<p>​           $\overline x_T$ = 1/T$\sum_{t=1}^tx_t$ ,是到t时刻，观测值的平均值</p>
<p>​           $\delta$ ,可以容忍的错误或者变化 the magnitude of changes allowed</p>
<p>$M_T$ = $min(m_t , t=1…T)$ , 变量观测值的最小值</p>
<p>$PH_T = m_T - M_T$  </p>
<p>$PH_T$ 和 $\lambda$ 进行比较，$PH_T$  $&gt;\lambda$ 则检测到变化，则进行剪枝</p>
<p>——————评价指标———————2ws</p>
<p>正确性✅和性能指标</p>
<p>正确性的保证通过hoeffding equlaity 满足保证</p>
<p>性能指标：比较 mean absoulut error 以及 root mean squareed error ／ learning time</p>
<p>————————— 改进空间———————-</p>
<p>因为是对流数据进行学习，现有的算法都是关注在保证小数据量样本的情况下，splitting attribute的正确性问题</p>
<p>评价指标：Learning Model Trees From Envolving data streams</p>
<p>y</p>
<p>评价方法：需要考虑到模型随着时间的变化</p>
<p>（1）沿用批处理中的hold out评估方法，随着时间的推移，利用一个hold out的测试集，周期性评估模型当数据分布不变时，可以从数据分布中产生一个独立的测试集合；如果数据分布是变化的，那么测试结合中需要包含新产生的样本</p>
<p>（2）</p>
<p>稳定的数据流，需要与批处理的算法进行比较：</p>
<p>（1）模型质量：10份真实数据集 交叉验证；评价指标：</p>
<p>mean error ME ／ mean squared error MSE 均方误差／ relative error RE ／root relative squared error RRSE</p>
<p>／相关系数 CC</p>
<p>（2）均方误差的偏差-方差分解</p>
<p>（3）敏感性度量：</p>
<p>a. 稳定性 statbility  训练10次，看训练误差，训练时间，模型大小等因素</p>
<p>b.鲁棒性 robustness to noise 测试数据集中的数据样本和噪声的比例固定，调整训练样本与噪声的比例，0-0.75</p>
<p>然后评价模型的准确性和大小</p>
<p>c. 及时性 the anytime property  评估模型对于预测样本的预测速度／时间</p>
<p>d. 对内存限制的独立性 dependency on memory constraints  =&gt;分布式与流式结合 进行改进</p>
<p>e. 处理速度 processing speed</p>
<p>时变的数据流 time-changing stream</p>
<p>（1）变化监测 change detection</p>
<p>在构造数据上进行，因为变化和可控且已知</p>
<p>（2） 变化适应 change adaptation</p>
<p>stream dm</p>
<p>SGD learner pecption</p>
</div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://yeeex.gitee.io"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/大数据系统/">大数据系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="http://www.jianshu.com/u/590589380922" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Yeeex.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>