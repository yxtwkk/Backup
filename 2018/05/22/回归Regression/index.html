<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Regression | Yeeex</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><div id="link" rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"></div><div id="link" rel="stylesheet" href="https://libs.useso.com/js/font-awesome/4.2.0/css/font-awesome.min.css"></div><div id="link" rel="stylesheet" href="font-awesome-4.7.0/css/font-awesome.min.css"></div><link rel="stylesheet" href="https://libs.baidu.com/fontawesome/4.0.3/css/font-awesome.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Regression</h1><a id="logo" href="/.">Yeeex</a><p class="description">愿自由且开阔</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Regression</h1><div class="post-meta">May 22, 2018<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span></div><div class="post-content"><p>机器学习问题是，根据实际需求，设计训练函数集合，通过一定的方法，找到一个最优的函数，即可以分为三个步骤：</p>
<p>（1）定义函数集合</p>
<p>（2）确定衡量函数/模型好坏的标准（最常见的就是loss funcion + regularization 即，损失函数+正则化）</p>
<p>（3）根据确定的标准，从函数集合中选择最优的函数</p>
<a id="more"></a>
<p>根据不同的需求，我们可以将机器学习的任务分为三类：</p>
<p>（1）回归问题 regeression 即，最后输出的是数值</p>
<p>（2）分类问题 classification 即，最后输出的是样本类别</p>
<p>（3）结构化学习 Structured learning 即，最后输出的是结构化的结果（输出的结果较复杂，比如语音辨识或者机器翻译等）</p>
<p>根据不同的场景，可以将机器学习分为：</p>
<p>（1）监督学习 Supervised Learning</p>
<p>（2）无监督学习 Unsupervised Learning</p>
<p>（3）半监督学习 Semi-supervised learning</p>
<p>（4）迁移学习 Transfer Learning：训练样本与目标任务不相关（训练样本可以是有标记的，也可以是无标记的）</p>
<p>（5）强化学习 Reinforcement Learning</p>
<p>💡强化学习和监督学习的区别：监督学习会告诉模型，每一个训练样本的正确标签/输出；强化学习不会告诉模型正确的输出应该是什么，只会告诉模型，如果按照这样行为去做，最终会得多少分（即，奖励机制）</p>
<hr>
<h3 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h3><p><strong>回归问题</strong></p>
<p>（1）定义函数集合，即设计模型：需要利用先验知识来确定模型：<script type="math/tex">y=wx+b</script>  这里<script type="math/tex">w</script> <script type="math/tex">b</script> <script type="math/tex">x</script> 都是向量，可以有多维</p>
<p>（2）确定衡量函数/模型好坏的标准：平方损失函数=&gt;模型优化采用梯度下降Gradient Descent方法</p>
<p>（3）采用梯度下降的方法优化模型，找到损失函数最小的参数$w$ 和$b$</p>
<h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><p><strong>梯度下降</strong></p>
<p>我就是这里被老师圈粉的 哈哈！梯度下降和偏差方差那部分讲的真的很棒！</p>
<p>从函数的角度，如果此刻在某一点（x,y）函数的梯度为负，则增加x，会使得y变小；反之，如果这一点函数的梯度为正，则增加x，会使得y变大</p>
<p>对于平方损失函数：</p>
<script type="math/tex; mode=display">w^{*},b^{*} = arg{min_{w,b}L(w,b)} = arg{min_{w,b}\sum_{n=1}^{N}(\hat{y}^n-(b+w*x_{i}) )^2}</script><p>而为了达到<strong>最小化损失函数</strong>的目的，如果函数的梯度为负，则增大变量$w​$，如果函数梯度为正，则减小变量$w​$</p>
<p>参数更新公式：</p>
<p>$w^{i+1} = w^{i} - \eta \frac{\partial L}{\partial w}$</p>
<p>$b^{i+1} = b^{i} - \eta \frac{\partial L}{\partial b}$              $\eta&gt;0$</p>
<p>（1）梯度下降中的初始化参数是随机的，初始化不同会得到不同的最优解</p>
<p>（2）优化的目标是使得损失函数最小即为0，但是实际操作中，当损失函数优化到一个较小的值时，就视为收敛</p>
<p>（3）在梯度下降更新参数时，不会保证每次参数更新以后，损失函数会更小</p>
<h3 id="Generalization"><a href="#Generalization" class="headerlink" title="Generalization"></a>Generalization</h3><p><strong>模型泛化能力</strong></p>
<p>（1）模型是否是线性的，取决于参数对于输出是否是线性的，即$w$ </p>
<p>（2）模型泛化能力是指训练得到的模型，在测试集合上的误差，误差越大，泛化能力越差</p>
<p>（3）越复杂的函数，其实包含了简单的函数，所以函数模型越复杂，训练误差会越低：</p>
<script type="math/tex; mode=display">
y_1 = \vec{b} +\vec{w _{1}}*\vec x + \vec w _{2}* \vec x^2</script><script type="math/tex; mode=display">
y_2 = \vec{b} +\vec{w _{1}}*\vec x</script><p>函数y1的函数空间包含了函数y2，只需要令$\vec w _{2}$为0向量就可以</p>
<p>所以，在函数y2上可以达到的最小训练误差，在函数y1上也可以达到</p>
<p>（4）过拟合问题</p>
<p>过拟合是指在训练样本上达到很小的训练误差，但是在测试样本上有很大的测试误差</p>
<p>解决过拟合的几种方法：</p>
<p>a. 收集更多的训练数据进行训练</p>
<p>b. 重新设计模型，可能存在一些hidden factor隐藏因素是最初没有考虑到的</p>
<p>c. 正则化Regularization：对于loss functin增加正则化项</p>
<script type="math/tex; mode=display">L ={\sum_{n=1}^{N}(\hat{y}^n-(b+w*x_{i}) )^2} + \lambda \sum (w_{i})^2</script><p>正则化项即所有参数的平方和，其中$\lambda$是正则化项的权重</p>
<p>$\lambda$越大，则最后得到的模型越平滑，当然，对应的训练误差也会越大</p>
<p>对于模型参数w，其表征的函数平滑程度，w越小，函数越平滑</p>
<p>（所谓平滑的意思就是，<script type="math/tex">y+\sum w _{i} \bigtriangleup x _{i} = b + \sum w _{i}(x _{i} + \bigtriangleup x _{i})</script>，<script type="math/tex">\sum w _{i} \bigtriangleup x _{i}</script> x的变化导致y的变化小）</p>
<p>💡我们这里其实假设，smooth的函数可能是更正确的</p>
<p>💡对于偏置项 $b$ 是不需要正则化的，因为正则化的意义是平滑模型函数，但是偏置$b$对于模型的平滑无影响（b的大小只是改变模型的平行移动）</p>
<hr>
<p>课程里提到一个问题，我觉得还挺有意思的：</p>
<p>设$x_{s} $ = species  of  x </p>
<p>if $x_{s} $= p :   $y = \vec{b_{1}} +\vec{w _{1}}*\vec x $</p>
<p>if $x_{s} ​$ = w:  $y = \vec{b_{2}} +\vec{w _{2}}*\vec x ​$</p>
<p>if $x_{s} $ = c:   $y = \vec{b_{3}} +\vec{w _{3}}*\vec x $</p>
<p>这样的模型是否是线性的？</p>
<p>引入$\delta(x_{s} = p)$ 函数 ：$\delta(x_{s} = p)$ = 1 if $x_{s} $= p ，else   $\delta(x_{s} = p) = 0$</p>
<p>则原模型可以改写为：</p>
<script type="math/tex; mode=display">y = \vec{b_{1}} \delta(x_{s} ) +\delta(x_{s}) \vec{w _{1}}*\vec x  +  \delta(x_{s} ) \vec{b_{2}} +\delta(x_{s}) \vec{w _{2}}*\vec x + \delta(x_{s}) \vec{b_{3}} +\delta(x_{s})\vec{w _{3}}*\vec x</script></div><div class="tags"></div><div class="post-nav"><a class="pre" href="/2018/05/23/偏差方差分解/">Bias-Variance Decompostion</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://yeeex.gitee.io"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/大数据系统/">大数据系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="http://www.jianshu.com/u/590589380922" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Yeeex.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>