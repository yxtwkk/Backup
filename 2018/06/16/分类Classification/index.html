<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Classification | Yeeex</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><div id="link" rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"></div><div id="link" rel="stylesheet" href="https://libs.useso.com/js/font-awesome/4.2.0/css/font-awesome.min.css"></div><div id="link" rel="stylesheet" href="font-awesome-4.7.0/css/font-awesome.min.css"></div><link rel="stylesheet" href="https://libs.baidu.com/fontawesome/4.0.3/css/font-awesome.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Classification</h1><a id="logo" href="/.">Yeeex</a><p class="description">愿自由且开阔</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Classification</h1><div class="post-meta">Jun 16, 2018<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span></div><div class="post-content"><p>分类问题和回归问题是机器学习中非常常见的两个学习任务，通常情况下，如果目标输出$y$ 是连续值，则为回归问题；如果目标输出$y$是类别标签，则为分类问题</p>
<p>分类问题的应用场景很多：</p>
<p>（1）信用卡申请：根据申请人的个人情况判断是否给予其信用卡：accept/refuse =&gt;二分类问题</p>
<p>（2）疾病检测：根据病人的身体特征判断其所患疾病 =&gt; 多分类问题</p>
<p>（3）手写体识别</p>
<p>（4）面部识别</p>
<a id="more"></a>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><h4 id="分类-vs-回归："><a href="#分类-vs-回归：" class="headerlink" title="分类 vs 回归："></a>分类 vs 回归：</h4><p>（1）每一个多分类问题都可以转换成一个二分类问题</p>
<p>（2）每一个二分类问题又可以转换成一个回归问题：</p>
<p>训练过程：Class 1对应的回归值是1，Class 2对应的回归值是-1；</p>
<p>测试过程：如果输出接近1，则测试样本的类别为1，如果输出接近-1，则测试样本的类别为2</p>
<p>可是这回带来一个问题：</p>
<p><strong>用regreesion训练模型，损失函数loss function会去惩罚“非常正确”的点</strong></p>
<p><img src="/2018/06/16/分类Classification/c1.png" width="300px"></p>
<p>假设特征空间为2维$(x1,x2)$，蓝色为class 1，红色为class 2，训练过程中，要求class 1的点的输出尽可能为1，class 2的输出尽可能为-1（进行充分拟合），对于这种聚合很好的分类问题，用回归来进行分类学习是可以实现的，但是，如何类别样本的数据比较分散，则会出现问题：</p>
<p><img src="/2018/06/16/分类Classification/c2.png" width="300px"></p>
<p>如果还是使用绿色这条线代表Regression的模型，则对于右下角的模型，其输出会远大于1，但是其目标输出为1，则Regression模型就会惩罚这些点，最后的模型会向这些远大于1的点倾斜为紫色这一条</p>
<p><strong>对于Regression，紫色的模型是一个合适的模型；对于Classification，绿色的模型是一个合适的模型</strong></p>
<p>另外，对于多分类问题，Class 1的回归值为1，Class 2的回归值为2，Class 3的回归值为3 =&gt;这会错误的传达出一个信息，即 Class 3和Class 2有关，Class 2和Class 1有关（因为其回归值近似）</p>
<hr>
<h3 id="分类模型"><a href="#分类模型" class="headerlink" title="分类模型"></a>分类模型</h3><p>函数模型：$f(x)$  =&gt; 输出class 1／class 2…</p>
<p>损失函数：$L(f) = \sum_{n} \delta (f(x^n) \neq\hat{y})$ (即，分类错误的样本数)</p>
<h4 id="概率角度："><a href="#概率角度：" class="headerlink" title="概率角度："></a>概率角度：</h4><p><img src="/2018/06/16/分类Classification/c3.png" width="400px"></p>
<p>现在有一个蓝色小球，判断其来自Box1的概率为：</p>
<p><img src="/2018/06/16/分类Classification/c6.png" width="400px"></p>
<p>更一般的，将Box 1和Box 2堪看成两个类别Class 1 和 Class 2，我们可以得出概率公式为：</p>
<p><img src="/2018/06/16/分类Classification/c4.png" width="300px"></p>
<p>小球$p(x)$的全概率为其生成模型：</p>
<p><img src="/2018/06/16/分类Classification/c5.png" width="300px"></p>
<p>计算公式中的 $p(x|C_1) $   $p(x|C_2)$  $p(C_1)$  $p(C_2)$ 都可以从训练样本中估计得到</p>
<hr>
<h4 id="高斯判别分析-GDA"><a href="#高斯判别分析-GDA" class="headerlink" title="高斯判别分析 GDA"></a>高斯判别分析 GDA</h4><p>以pokerman的训练数据为例，假设水系的pokerman可以通过$ <sp defense,="" defense="">$两个特征来表示</sp></p>
<p>训练样本选取了79只，现在有一个新来的样本$ <sp defense="103,">$ </sp></p>
<p>如何知道从水系的pokerman中选出这个样本的概率 $p(x|水系)$ </p>
<p><img src="/2018/06/16/分类Classification/c7.png" width="400px"></p>
<p><strong>一般情况下，会假设训练样本（如图所示为79个训练样本点）是从一个高斯分布（Gassion Distribution）中抽样得到</strong> </p>
<p>=&gt; 问题转换成 如何根据训练样本，学习得到这个高斯分布</p>
<p>多维高斯概率密度函数<img src="/2018/06/16/分类Classification/c8.png" width="400px"></p>
<p>其参数有两个：$\mu$：均值   $\Sigma$：协方差矩阵 =&gt;概率密度函数由这两个参数决定</p>
<p>=&gt; 问题转换成 如何估计这两个参数</p>
<h5 id="极大似然估计-Maximum-Likelihood-Estimate"><a href="#极大似然估计-Maximum-Likelihood-Estimate" class="headerlink" title="极大似然估计 Maximum Likelihood Estimate"></a>极大似然估计 Maximum Likelihood Estimate</h5><p>对于训练样本的79个点，任何一个高斯分布都可以生成这样79个点，只不过是不同分布生成这些点的概率不同，则如果已知某一个高斯分布的$\mu$ $\Sigma$，我们就可以知道其产生这79个点的likelihood：</p>
<p>（所有的79个点是独立被采样得到，所以可以通过乘积计算）</p>
<p><img src="/2018/06/16/分类Classification/c9.png" width="400px"></p>
<p>💡注意此处的L和loss function的L不是一个L！！</p>
<p>穷尽不同的$\mu$ $\Sigma$，得到使得$L(\mu,\Sigma)$最大的参数：</p>
<p><img src="/2018/06/16/分类Classification/c10.png" width="200px"></p>
<p>=&gt;通过微分求极值，得到的结果为：</p>
<script type="math/tex; mode=display">\mu^* = \frac{1}{79}\sum_{n=1}^{79}x^n</script><script type="math/tex; mode=display">\Sigma^* = \frac{1}{79}\sum_{n=1}^{79}(x^n-\mu^*)(x^n-\mu^*)^T</script><p>$x^n$ :每一个训练样本</p>
<p>举个例子🌰：</p>
<p>假设现在从两个不同的高斯分布中采样得到两种类型的神奇宝贝：79只水系神奇宝贝和61只正常的神奇宝贝，则根据上面所述的极大似然估计，可以得到水系神奇宝贝的高斯分布和正常神奇宝贝的高斯分布</p>
<p><img src="/2018/06/16/分类Classification/c11.png" width="400px"></p>
<p>则分类问题</p>
<p>$P(C_1|x) = \frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1) +P(x|C_2)P(C_2)}$</p>
<p>$P(x|C_1)$ ：根据估计得到的高斯密度公式，可以求得</p>
<p>$P(C_1)= \frac{79}{79+61}= 0.56$ </p>
<h4 id="如何提高准确率"><a href="#如何提高准确率" class="headerlink" title="如何提高准确率"></a>如何提高准确率</h4><p>（1）增加训练样本数目</p>
<p>（2）增加训练样本维度，前面是在二维情况下分类，但是低维不可分的情况，在高维也许是可分的；在高纬不可分的情况下， 在低维也许是可分的</p>
<p>如何在训练样本有限的情况下，如何提高测试样本的测试准确率？</p>
<p><strong>不同的类别共用相同的协方差矩阵</strong> ，因为协方差矩阵是和样本特征维度的平方成正比的，当样本特征维度很高时，协方差矩阵很大，这会导致模型参数过多，会造成模型过拟合=&gt; variance过大 </p>
<p><strong>具体方法</strong>：继续沿用上面的例子，假设有79只神奇宝贝来自水系，61只神奇宝贝为正常的</p>
<p>$L(\mu^1,\mu^2,\Sigma) = f_{\mu^1,\Sigma}(x^1)f_{\mu^1,\Sigma}(x^2)…f_{\mu^1,\Sigma}(x^{79})*f_{\mu^2,\Sigma}(x^{80})…f_{\mu^2,\Sigma}(x^{140})$</p>
<p>对函数求导之后可以得到：</p>
<p>$\mu_1^* = \frac{1}{79}\sum_{n=1}^{79}x^n$</p>
<p>$\mu_2^* = \frac{1}{61}\sum_{n=80}^{140}x^n$</p>
<script type="math/tex; mode=display">\Sigma = P(C_1)*\Sigma^1 + P(C_2)*\Sigma^2 =\frac{79}{79+61}*\Sigma^1 + \frac{61}{79+61}*\Sigma^2</script><p>💡<strong>为什么使用高斯分布估计样本的分布？</strong></p>
<p>可以使用任何的概率分布模型，这是一个超参数，需要提前设定</p>
<hr>
<h4 id="朴素贝叶斯分类"><a href="#朴素贝叶斯分类" class="headerlink" title="朴素贝叶斯分类"></a>朴素贝叶斯分类</h4><p>训练样本$x=[x_1,x_2,x_3…x_k]$</p>
<p>💡假设每一个维度的产生是独立的，则可以将似然写成：（将每个维度估计成1-D Gaussian 正太分布）</p>
<p>$P(x|C_1) = P(x_1|C_1)P(x_2|C_1)…P(x_k|C_1)$</p>
<p>如果不考虑维度之间的协方差关系，则这种模型为朴素贝叶斯模型 <strong>Naive Bayes Classifier</strong>，即</p>
<p>$P(C_1|x) \;oc\; P(x|C_1)P(C_1) =P(x_1|C_1)P(x_2|C_1)…P(x_k|C_1)P(C_1) $</p>
<p>分类器好坏和假设的强弱正相关！</p>
<p>💡如果某个属性是binary的，比如是或不是，或者0／1</p>
<p>则可以假设这个属性是伯努利分布Bernoulli Distribution</p>
<p>💡对后验概率进行处理，则可以得到Sigmoid function：</p>
<p><img src="/2018/06/16/分类Classification/c12.png" width="400px"></p>
<p><img src="/2018/06/16/分类Classification/c13.png" width="200px"></p>
<p><strong>Sigmoid function</strong>：</p>
<p><img src="/2018/06/16/分类Classification/c14.png" width="200px"></p>
<p>z趋近于正无穷大的时候，其output趋近于1；z趋近于负无穷大的时候，其output趋近于0</p>
<hr>
<h4 id="P-C-1-x-sigma-z"><a href="#P-C-1-x-sigma-z" class="headerlink" title="$P(C_1|x) = \sigma (z)$"></a>$P(C_1|x) = \sigma (z)$</h4><script type="math/tex; mode=display">z = ln\frac{|\Sigma^2|^{1/2}}{|\Sigma^1|^{1/2}} - \frac{1}{2}x^T(\Sigma^1)^{-1}x + (\mu^1)^T(\Sigma^1)^{-1}x - \frac{1}{2}(\mu^1)^T(\Sigma^1)^{-1}\mu^1 + \frac{1}{2}x^T(\Sigma^2)^{-1}x - (\mu^2)^T(\Sigma^2)^{-1}x + \frac{1}{2} (\mu^2)^T(\Sigma^2)^{-1}\mu^2 +ln\frac{N_1}{N_2}</script><p>因为假设两个类别共用一个协方差矩阵，则z可以写成，并提取x：</p>
<p><img src="/2018/06/16/分类Classification/c18.png" width="400px"></p>
<p>因此，$P(C_1|x) = \sigma (z)= \sigma (w·x+b)$</p>
<p>因此，当共用协方差矩阵时，分类界面是线性的</p>
<p>参数w和b可以通过$N_1$   $N_2$   $\mu^1$  $\mu^2$ $\Sigma$</p>
<p><strong>附推导过程</strong></p>
<p><img src="/2018/06/16/分类Classification/c15.png" width="400px"></p>
<p><img src="/2018/06/16/分类Classification/c16.png" width="400px"></p>
<p><img src="/2018/06/16/分类Classification/c17.png" width="400px"></p>
</div><div class="tags"></div><div class="post-nav"><a class="pre" href="/2018/06/20/逻辑回归Logistic-Regression/">Logistic Regression</a><a class="next" href="/2018/05/31/Gradient-Descent/">Gradient Descent</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://yeeex.gitee.io"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/大数据系统/">大数据系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="http://www.jianshu.com/u/590589380922" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Yeeex.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>